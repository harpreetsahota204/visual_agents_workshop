{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JbrOcNz1UyQZ",
      "metadata": {
        "id": "JbrOcNz1UyQZ"
      },
      "outputs": [],
      "source": [
        "!pip install fiftyone qwen-vl-utils accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c159c07",
      "metadata": {
        "id": "7c159c07"
      },
      "source": [
        "# Using GUI Actor in FiftyOne\n",
        "\n",
        "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/visual_agents_workshop/blob/main/session_3/Testing_GUI_Actor_3B_on_FiftyOne_App_Dataset.ipynb)\n",
        "# \n",
        "\n",
        "\n",
        "This tutorial demonstrates how to use the GUI-Actor vision-language models with FiftyOne for various visual understanding tasks.\n",
        "\n",
        "Note: This is the model that we are going to fine-tune. First, we will see it's performance without fine-tuning.\n",
        "\n",
        "\n",
        "## Load a Sample Dataset\n",
        "\n",
        "First, let's load a UI dataset from the [FiftyOne Hugging Face Org](https://huggingface.co/Voxel51)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d9d6ba",
      "metadata": {
        "id": "51d9d6ba"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "dataset = load_from_hub(\n",
        "    \"harpreetsahota/FiftyOne-GUI-Grounding-Eval\",\n",
        "    overwrite=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac89947",
      "metadata": {
        "id": "bac89947"
      },
      "source": [
        "Launch the FiftyOne App to visualize the dataset (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37ca651",
      "metadata": {
        "id": "d37ca651"
      },
      "outputs": [],
      "source": [
        "fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcbb8d21",
      "metadata": {
        "id": "dcbb8d21"
      },
      "source": [
        "Take a look at the first sample and instruction to get a sense of what is in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3572837",
      "metadata": {
        "id": "f3572837"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "Image.open(dataset.first().filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269ed1b2",
      "metadata": {
        "id": "269ed1b2"
      },
      "outputs": [],
      "source": [
        "dataset.first().task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9065f657",
      "metadata": {
        "id": "9065f657"
      },
      "source": [
        "## Set Up GUI-Actor Integration\n",
        "\n",
        "Register the GUI-Actor remote zoo model source and load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710ffc9b",
      "metadata": {
        "id": "710ffc9b",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Register the model source\n",
        "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/gui_actor\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80e0985",
      "metadata": {
        "id": "f80e0985"
      },
      "source": [
        "# Load the `GUI-Actor-3B-Qwen2.5-VL` model\n",
        "\n",
        "You can also use `GUI-Actor-7B-Qwen2.5-VL`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96097cf9",
      "metadata": {
        "id": "96097cf9"
      },
      "outputs": [],
      "source": [
        "model = foz.load_zoo_model(\n",
        "    \"microsoft/GUI-Actor-3B-Qwen2.5-VL\",\n",
        "    # install_requirements=True, #you can pass this to make sure you have all reqs installed\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc9c157",
      "metadata": {
        "id": "9fc9c157"
      },
      "outputs": [],
      "source": [
        "dataset.apply_model(\n",
        "    model,\n",
        "    prompt_field=\"task\",\n",
        "    label_field=\"guiactor_output\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9997a5",
      "metadata": {
        "id": "cf9997a5"
      },
      "source": [
        "#### Adding Attention Heatmaps to Dataset\n",
        "\n",
        "Since FiftyOne models can only return one prediction type (`keypoints` in our case), we save the attention heatmaps as PNG files during inference and need to manually link them back to the dataset.\n",
        "\n",
        "This allows us to visualize both the predicted interaction points and the model's attention patterns together in the FiftyOne app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1f7c23",
      "metadata": {
        "id": "0c1f7c23"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "for sample in dataset:\n",
        "    # Generate expected heatmap path\n",
        "    original_path = Path(sample.filepath)\n",
        "    heatmap_path = original_path.parent / f\"{original_path.stem}_attention.png\"\n",
        "\n",
        "    if heatmap_path.exists():\n",
        "        # Add heatmap field using the saved PNG file\n",
        "        sample[\"attention_heatmap\"] = fo.Heatmap(map_path=str(heatmap_path))\n",
        "        sample.save()\n",
        "    else:\n",
        "        print(f\"Heatmap not found for {sample.filepath}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b797fea4",
      "metadata": {
        "id": "b797fea4"
      },
      "source": [
        "Take a look at the first Sample to ensure we have parsed the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42fd5fa8",
      "metadata": {
        "id": "42fd5fa8"
      },
      "outputs": [],
      "source": [
        "dataset.first()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89bdf076",
      "metadata": {
        "id": "89bdf076"
      },
      "outputs": [],
      "source": [
        "# Visualize all results in the FiftyOne App\n",
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93933402",
      "metadata": {
        "id": "93933402"
      },
      "outputs": [],
      "source": [
        "session.freeze()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
